{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io.collection import ImageCollection\n",
    "from skimage.io import imread\n",
    "from joblib import Parallel,delayed\n",
    "from typing import Tuple, List\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "   Load images from DataBase and QuerySets\n",
    "\"\"\"\n",
    "def load_data() -> Tuple[np.ndarray,np.ndarray,np.ndarray]:\n",
    "    db = ImageCollection(\"../data/BBDD/*.jpg\")\n",
    "    print('BBDD read: {} images'.format(len(db)))\n",
    "    qs1 = ImageCollection(\"../data/qsd1_w1/*.jpg\")\n",
    "    print('QuerySet1 read: {} images'.format(len(qs1)))\n",
    "    qs2 = ImageCollection(\"../data/qsd2_w1/*.jpg\")\n",
    "    print('QuerySet2 read: {} images'.format(len(qs2)))\n",
    "    \n",
    "    return db, qs1, qs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "   Computes image's histograms for each color channel (r,g,b) and concatenates them\n",
    "   to create a feature vector\n",
    "\"\"\"\n",
    "def get_histogram_vector(image: np.ndarray,n_bins: int = 16) -> np.ndarray:\n",
    "   r_hist = np.histogram(image[:, :, 0],bins=n_bins)[0]\n",
    "   g_hist = np.histogram(image[:, :, 1],bins=n_bins)[0]\n",
    "   b_hist = np.histogram(image[:, :, 2],bins=n_bins)[0]\n",
    "   feature_vector = np.hstack((r_hist,g_hist,b_hist))\n",
    "   return feature_vector\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "   Computes feature vector for each image of our dataset.\n",
    "\"\"\"    \n",
    "def get_feature_matrix(dataset: np.ndarray, desc: str, n_bins: int = 16) -> np.ndarray:\n",
    "   feature_matrix = Parallel(n_jobs=2)(delayed(get_histogram_vector)(image,n_bins)for image in tqdm(dataset,desc=desc))\n",
    "   return np.array(feature_matrix)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "   Computes cos similarity between feature vector and all BBDD feature vectors\n",
    "\"\"\"    \n",
    "def cos_similarity(vector: np.ndarray) -> np.ndarray:\n",
    "    return db_feature_matrix.dot(vector)/ (np.linalg.norm(db_feature_matrix, axis=1) * np.linalg.norm(vector))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "   Computes cos similairty for an entire QuerySet\n",
    "\"\"\"    \n",
    "def compute_similarities(qs: np.ndarray,desc: str) -> np.ndarray:\n",
    "    return np.array([cos_similarity(vector) for vector in tqdm(qs,desc=desc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "   Retrieves the top k similar images for a vector.\n",
    "\"\"\"    \n",
    "def get_top_k_vector(similarity_vector: np.ndarray, k: int) -> List[str]:\n",
    "    idx = np.argpartition(similarity_vector, -k)[-k:]\n",
    "    top_k = list(similarity_vector[idx])\n",
    "    sorted_top = list(sorted(top_k,reverse=True))\n",
    "    idx = [idx[top_k.index(i)] for i in sorted_top]\n",
    "    return [db.files[i] for i in idx]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "   Retrieves the top k similar images for a QuerySEt\n",
    "\"\"\"    \n",
    "def get_top_k(similarity_matrix: np.ndarray, k: int, desc: str) -> List[List[str]]:\n",
    "    return [get_top_k_vector(vector,k) for vector in tqdm(similarity_matrix, desc = desc)]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "   Retrieves the top k similar images for a vector.\n",
    "\"\"\"    \n",
    "def get_bot_k_vector(similarity_vector: np.ndarray, k: int) -> List[str]:\n",
    "    idx = similarity_vector.argsort()[:k]\n",
    "    bot_k = list(similarity_vector[idx])\n",
    "    sorted_bot = list(sorted(bot_k,reverse=False))\n",
    "    idx = [idx[bot_k.index(i)] for i in sorted_bot]\n",
    "    return [db.files[i] for i in idx]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "   Retrieves the bot k similar images for a QuerySet.\n",
    "\"\"\"    \n",
    "def get_bot_k(similarity_matrix: np.ndarray, k: int, desc: str) -> List[List[str]]:\n",
    "    return [get_bot_k_vector(vector,k) for vector in tqdm(similarity_matrix, desc = desc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "   Plot Base Image and top 3 closest images\n",
    "\"\"\"   \n",
    "def plot_image_and_similar(image,similar):\n",
    "    f, axarr = plt.subplots(2,2, figsize=(10,10))\n",
    "    axarr[0,0].imshow(image)\n",
    "    axarr[0,0].title.set_text(\"Base\")\n",
    "    axarr[0,1].imshow(similar[0])\n",
    "    axarr[0,1].title.set_text(\"Query 1\")\n",
    "    axarr[1,0].imshow(similar[1])\n",
    "    axarr[1,0].title.set_text(\"Query 2\")\n",
    "    axarr[1,1].imshow(similar[2])\n",
    "    axarr[1,1].title.set_text(\"Query 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db, qs1, qs2 = load_data()\n",
    "\n",
    "db_feature_matrix = get_feature_matrix(dataset = db, n_bins = 16, desc = \"Creating feature matrix for BBDD...\")\n",
    "qs1_feature_matrix = get_feature_matrix(dataset = qs1, n_bins = 16, desc = \"Creating feature matrix for QuerySet1...\")\n",
    "qs2_feature_matrix = get_feature_matrix(dataset = qs2, n_bins = 16, desc = \"Creating feature matrix for QuerySet2...\")\n",
    "\n",
    "qs1_similarities = compute_similarities(qs = qs1_feature_matrix, desc = \"Computing qs1 similarities...\")\n",
    "qs2_similarities = compute_similarities(qs = qs2_feature_matrix, desc = \"Computing qs2 similarities...\")\n",
    "\n",
    "top_k_qs1 = get_top_k(qs1_similarities, 3, desc = \"Retrieving qs1 top K similar images...\")\n",
    "top_k_qs2 = get_top_k(qs2_similarities, 3, desc = \"Retrieving qs2 top K similar images...\")\n",
    "\n",
    "bot_k_qs1 = get_bot_k(qs1_similarities, 3, desc = \"Retrieving qs1 bot K similar images...\")\n",
    "bot_k_qs2 = get_bot_k(qs2_similarities, 3, desc = \"Retrieving qs2 bot K similar images...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example plot 1\n",
    "plot_image_and_similar(qs1[0],[imread(image) for image in top_k_qs1[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example plot 2\n",
    "plot_image_and_similar(qs1[1],[imread(image) for image in top_k_qs1[1]])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b57afa678a37970e2ae1e97bfae723b2640c4399908e06bd470e86425548b2c3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
