{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Own Libraries\n",
    "from utils.data import load_data\n",
    "from utils.metrics import prec_recall, iou_score, f1_dice\n",
    "from utils.similarity import Similarity\n",
    "from utils.image_processing import image_to_windows, get_3d_norm_histogram, calculate_histograms\n",
    "# 3rd Party Libraries\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from typing import Tuple, List\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import ml_metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db_feature_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2604ea866493>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb_feature_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"figure.figsize\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mxi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m288\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'db_feature_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "pca = PCA().fit(db_feature_matrix)\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "fig, ax = plt.subplots()\n",
    "xi = np.arange(1, 288, step=1)\n",
    "y = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.ylim(0.0,1.1)\n",
    "plt.plot(xi, y, marker='o', linestyle='--', color='b')\n",
    "\n",
    "plt.xlabel('Number of Components')\n",
    "plt.xticks(np.arange(0, 288, step=5)) #change from 0-based array index to 1-based human-readable label\n",
    "plt.ylabel('Cumulative variance (%)')\n",
    "plt.title('The number of components needed to explain variance')\n",
    "\n",
    "plt.axhline(y=0.95, color='r', linestyle='-')\n",
    "plt.text(0.5, 0.85, '95% cut-off threshold', color = 'red', fontsize=16)\n",
    "\n",
    "ax.grid(axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "   Retrieves the top k similar images for a vector.\n",
    "\"\"\"    \n",
    "def get_top_k_vector(similarity_vector: np.ndarray, k: int) -> List[str]:\n",
    "   # We get top K index of the vector (unordered)\n",
    "   idx = np.argpartition(similarity_vector, -k)[-k:]\n",
    "   \n",
    "   # Then we order index in order to get the ordered top k values\n",
    "   top_k = list(similarity_vector[idx])\n",
    "   sorted_top = list(sorted(top_k,reverse=True))\n",
    "   idx = [idx[top_k.index(i)] for i in sorted_top]\n",
    "   \n",
    "   # ImageCollection also saves in .files so we can easily retrieve them\n",
    "   return [db_files[i] for i in idx]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "   Retrieves the top k similar images for a QuerySEt\n",
    "\"\"\"    \n",
    "def get_top_k(similarity_matrix: np.ndarray, k: int, desc: str) -> List[List[str]]:\n",
    "   # Estimate top k values for all the Queryet\n",
    "   return [get_top_k_vector(vector,k) for vector in tqdm(similarity_matrix, desc = desc)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "   Plot 1st Query Results\n",
    "\"\"\"   \n",
    "def plot_image_and_similar(qs,top_qs) -> None:\n",
    "    \n",
    "    for i in range(len(qs)):\n",
    "        f, axarr = plt.subplots(1,2, figsize=(10,10))\n",
    "        base = qs[i]\n",
    "        print(top_qs[i])\n",
    "        query = imread(top_qs[i][0])\n",
    "        axarr[0].imshow(base)\n",
    "        axarr[0].title.set_text(\"Base\")\n",
    "        axarr[1].imshow(query)\n",
    "        axarr[1].title.set_text(\"Query\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Image path to ID\n",
    "\"\"\"\n",
    "def get_image_id(image: str) -> str:\n",
    "    # Extract BBBD_XXX.jpg from relative path\n",
    "    file = image.split(\"/\")[3]\n",
    "    # Extract XXX id from BBBD_XXX.jpg \n",
    "    id = file.replace(\".jpg\",\"\").split(\"_\")[1]\n",
    "    return int(id)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Save Results properly formated\n",
    "\"\"\"\n",
    "def save_results(results: List[List[str]], path: str, save: bool) -> None:\n",
    "    # Vectorize function to apply to each element in results\n",
    "    get_ids = np.vectorize(get_image_id)\n",
    "    results = get_ids(results)\n",
    "\n",
    "    \n",
    "    # Creates Save Folder \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    if save:\n",
    "    # Saves data\n",
    "        pickle.dump(obj = results,file = open(path+\"/result.pkl\",\"wb\"))\n",
    "        print(\"Results Saved!\")\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [i for i in range(len(qst2_w2_files))]\n",
    "for element in idx:\n",
    "    topk = []\n",
    "    topk.append(top_k_qst2_w2[element[0][1]])\n",
    "    if len(element) == 2:\n",
    "        topk.append(top_k_qst2_w2[element[1][1]])\n",
    "    \n",
    "    results[element[0][0]] = topk\n",
    "\n",
    "result = []\n",
    "for element in results:   \n",
    "    tmp = []\n",
    "    for image in element:\n",
    "        a = [get_image_id(string) for string in image]\n",
    "        tmp.append(a)\n",
    "\n",
    "    if len(tmp) == 1:\n",
    "        tmp = tmp[0]\n",
    "    \n",
    "    result.append(tmp)\n",
    "\n",
    "pickle.dump(obj = result,file = open(\"./week2/QST2/method1\"+\"/result.pkl\",\"wb\"))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'data/qst2_w2/00000.jpg': [(566, 92, 1243, 639), (74, 178, 296, 458)],\n",
    " 'data/qst2_w2/00001.jpg': (64, 114, 1879, 2196),\n",
    " 'data/qst2_w2/00002.jpg': (92, 98, 740, 941),\n",
    " 'data/qst2_w2/00003.jpg': (94, 85, 1809, 2037),\n",
    " 'data/qst2_w2/00004.jpg': (109, 0, 1613, 2276),\n",
    " 'data/qst2_w2/00005.jpg': [(2231, 60, 3960, 1509), (137, 89, 1838, 1541)],\n",
    " 'data/qst2_w2/00006.jpg': (85, 87, 557, 664),\n",
    " 'data/qst2_w2/00007.jpg': [(74, 82, 635, 636), (172, 227, 574, 582)],\n",
    " 'data/qst2_w2/00008.jpg': [(506, 74, 780, 428), (100, 95, 340, 397)],\n",
    " 'data/qst2_w2/00009.jpg': (0, 82, 3602, 2424),\n",
    " 'data/qst2_w2/00010.jpg': (0, 0, 3613, 1883),\n",
    " 'data/qst2_w2/00011.jpg': (58, 85, 678, 681),\n",
    " 'data/qst2_w2/00012.jpg': (70, 0, 472, 542),\n",
    " 'data/qst2_w2/00013.jpg': (63, 125, 581, 643),\n",
    " 'data/qst2_w2/00014.jpg': (61, 0, 664, 788),\n",
    " 'data/qst2_w2/00015.jpg': (0, 0, 2150, 859),\n",
    " 'data/qst2_w2/00016.jpg': (80, 62, 1715, 2022),\n",
    " 'data/qst2_w2/00017.jpg': [(61, 58, 461, 610), (135, 153, 391, 502)],\n",
    " 'data/qst2_w2/00018.jpg': [(0, 129, 1245, 882), (93, 156, 360, 742)],\n",
    " 'data/qst2_w2/00019.jpg': (82, 81, 517, 643),\n",
    " 'data/qst2_w2/00020.jpg': (115, 0, 1501, 1263),\n",
    " 'data/qst2_w2/00021.jpg': [(647, 139, 986, 435), (68, 180, 496, 378)],\n",
    " 'data/qst2_w2/00022.jpg': (133, 134, 1945, 1623),\n",
    " 'data/qst2_w2/00023.jpg': (83, 134, 332, 407),\n",
    " 'data/qst2_w2/00024.jpg': (84, 101, 475, 612),\n",
    " 'data/qst2_w2/00025.jpg': (68, 112, 519, 509),\n",
    " 'data/qst2_w2/00026.jpg': (150, 91, 1236, 1445),\n",
    " 'data/qst2_w2/00027.jpg': (131, 143, 589, 709),\n",
    " 'data/qst2_w2/00028.jpg': [(744, 141, 1415, 628), (100, 166, 558, 535)],\n",
    " 'data/qst2_w2/00029.jpg': [(107, 129, 592, 541), (0, 0, 159, 634)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_qst2():\n",
    "    cropped = []\n",
    "    cropped2 = []\n",
    "    for key in data:\n",
    "        idx = list(qst2_w2_files).index(\"./\"+key)\n",
    "        image = qst2_w2[idx]\n",
    "\n",
    "        qs = []\n",
    "\n",
    "        s = data[key]\n",
    "        if len(s) == 4:\n",
    "            s = [s]\n",
    "        for points in s:\n",
    "            c = image[points[1]:points[3],points[0]:points[2]]\n",
    "            qs.append((idx,len(cropped2)))\n",
    "            cropped2.append(c)\n",
    "\n",
    "        cropped.append(qs)\n",
    "\n",
    "    return cropped, cropped2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading BBDD Data...: 100%|██████████| 287/287 [00:11<00:00, 24.90it/s]\n",
      "Loading qsd2_w1 Data...:  23%|██▎       | 7/30 [00:00<00:00, 69.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/BBDD/ read: 287 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading qsd2_w1 Data...: 100%|██████████| 30/30 [00:00<00:00, 54.06it/s]\n",
      "Loading qsd1_w2 Data...:  17%|█▋        | 5/30 [00:00<00:00, 40.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/qsd2_w1/ read: 30 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading qsd1_w2 Data...: 100%|██████████| 30/30 [00:00<00:00, 83.82it/s]\n",
      "Loading qsd2_w2 Data...:   3%|▎         | 1/30 [00:00<00:02,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/qsd1_w2/ read: 30 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading qsd2_w2 Data...: 100%|██████████| 30/30 [00:01<00:00, 23.45it/s]\n",
      "Loading qst1_w2 Data...:  23%|██▎       | 7/30 [00:00<00:00, 64.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/qsd2_w2/ read: 30 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading qst1_w2 Data...: 100%|██████████| 30/30 [00:00<00:00, 95.43it/s]\n",
      "Loading qst2_w2 Data...:  20%|██        | 6/30 [00:00<00:00, 58.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/qst1_w2/ read: 30 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading qst2_w2 Data...: 100%|██████████| 30/30 [00:00<00:00, 41.54it/s]\n",
      "Cropping Images using Otsu method...:  13%|█▎        | 4/30 [00:00<00:00, 28.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/qst2_w2/ read: 30 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping Images using Otsu method...: 100%|██████████| 30/30 [00:01<00:00, 29.94it/s]\n",
      "Normalized 3D Histograms Calculation for BBDD...: 100%|██████████| 287/287 [00:01<00:00, 189.77it/s]\n",
      "Normalized 3D Histograms Calculation for qsd2_w1...: 100%|██████████| 30/30 [00:00<00:00, 406.70it/s]\n",
      "Normalized 3D Histograms Calculation for qsd1_w2...: 100%|██████████| 30/30 [00:00<00:00, 434.71it/s]\n",
      "Normalized 3D Histograms Calculation for qsd2_w2...: 100%|██████████| 30/30 [00:00<00:00, 107.91it/s]\n",
      "Normalized 3D Histograms Calculation for qst1_w2...: 100%|██████████| 30/30 [00:00<00:00, 537.75it/s]\n",
      "Normalized 3D Histograms Calculation for qst2_w2...: 100%|██████████| 39/39 [00:00<00:00, 338.51it/s]\n",
      "Computing qsd2_w1 similarities...: 100%|██████████| 30/30 [00:00<00:00, 1396.13it/s]\n",
      "Computing qsd1_w2 similarities...: 100%|██████████| 30/30 [00:00<00:00, 1375.72it/s]\n",
      "Computing qsd2_w2 similarities...: 100%|██████████| 30/30 [00:00<00:00, 1338.11it/s]\n",
      "Computing qst1_w2 similarities...: 100%|██████████| 30/30 [00:00<00:00, 1433.20it/s]\n",
      "Computing qst2_w2 similarities...: 100%|██████████| 39/39 [00:00<00:00, 1435.23it/s]\n",
      "Retrieving qsd2_w1 top K similar images...: 100%|██████████| 30/30 [00:00<00:00, 24409.14it/s]\n",
      "Retrieving qsd1_w2 top K similar images...: 100%|██████████| 30/30 [00:00<00:00, 37128.69it/s]\n",
      "Retrieving qsd2_w2 top K similar images...: 100%|██████████| 30/30 [00:00<00:00, 39556.47it/s]\n",
      "Retrieving qst1_w2 top K similar images...: 100%|██████████| 30/30 [00:00<00:00, 36261.99it/s]\n",
      "Retrieving qst2_w2 top K similar images...: 100%|██████████| 39/39 [00:00<00:00, 40680.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Saved!\n",
      "MAP@K Score(ostsu): 3.3333% (1/30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "db, db_files = load_data(\"./data/BBDD/\",\".jpg\", desc = \"Loading BBDD Data...\")\n",
    "qsd2_w1, qsd2_w1_files = load_data(\"./data/qsd2_w1/\",\".jpg\", desc = \"Loading qsd2_w1 Data...\")\n",
    "qsd1_w2, qsd1_w2_files = load_data(\"./data/qsd1_w2/\",\".jpg\", desc = \"Loading qsd1_w2 Data...\")\n",
    "qsd2_w2, qsd2_w2_files = load_data(\"./data/qsd2_w2/\",\".jpg\", desc = \"Loading qsd2_w2 Data...\")\n",
    "qst1_w2, qst2_w2_files = load_data(\"./data/qst1_w2/\",\".jpg\", desc = \"Loading qst1_w2 Data...\")\n",
    "qst2_w2, qst2_w2_files = load_data(\"./data/qst2_w2/\",\".jpg\", desc = \"Loading qst2_w2 Data...\")\n",
    "\n",
    "new_qsd2_w1, masks_1 = crop_images(qsd2_w1,method=\"otsu\")\n",
    "idx, new_qst2_w2 = crop_qst2()\n",
    "#new_qsd1_w2, masks_1 = crop_images(qsd1_w2,method=\"otsu\")\n",
    "#new_qsd2_w2, masks_1 = crop_images(qsd2_w2,method=\"otsu\")\n",
    "\n",
    "\n",
    "# 3D Normalized Histograms Multiresolutio/Block Images\n",
    "db_feature_matrix = calculate_histograms(db,16,n_rows=4,n_cols=4,desc=\"Normalized 3D Histograms Calculation for BBDD...\")\n",
    "qsd2_w1_feature_matrix = calculate_histograms(new_qsd2_w1,16,n_rows=4,n_cols=4,desc = \"Normalized 3D Histograms Calculation for qsd2_w1...\")\n",
    "qsd1_w2_feature_matrix = calculate_histograms(qsd1_w2,16,n_rows=4,n_cols=4,desc = \"Normalized 3D Histograms Calculation for qsd1_w2...\")\n",
    "qsd2_w2_feature_matrix = calculate_histograms(qsd2_w2,16,n_rows=4,n_cols=4,desc = \"Normalized 3D Histograms Calculation for qsd2_w2...\")\n",
    "qst1_w2_feature_matrix = calculate_histograms(qst1_w2,16,n_rows=4,n_cols=4,desc = \"Normalized 3D Histograms Calculation for qst1_w2...\")\n",
    "qst2_w2_feature_matrix = calculate_histograms(new_qst2_w2,16,n_rows=4,n_cols=4,desc = \"Normalized 3D Histograms Calculation for qst2_w2...\")\n",
    "\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "db_feature_matrix = pca.fit_transform(db_feature_matrix)\n",
    "qsd2_w1_feature_matrix = pca.transform(qsd2_w1_feature_matrix)\n",
    "qsd1_w2_feature_matrix = pca.transform(qsd1_w2_feature_matrix)\n",
    "qsd2_w2_feature_matrix = pca.transform(qsd2_w2_feature_matrix)\n",
    "qst1_w2_feature_matrix = pca.transform(qst1_w2_feature_matrix)\n",
    "qst2_w2_feature_matrix = pca.transform(qst2_w2_feature_matrix)\n",
    "\n",
    "# Similarity\n",
    "sim = Similarity()\n",
    "qs2_w1_similarities = sim.compute_similarities(qs = qsd2_w1_feature_matrix, db_feature_matrix = db_feature_matrix, desc = \"Computing qsd2_w1 similarities...\", similarity = 'hellinger')\n",
    "qs1_w2_similarities = sim.compute_similarities(qs = qsd1_w2_feature_matrix, db_feature_matrix = db_feature_matrix, desc = \"Computing qsd1_w2 similarities...\", similarity = 'hellinger')\n",
    "qs2_w2_similarities = sim.compute_similarities(qs = qsd2_w2_feature_matrix, db_feature_matrix = db_feature_matrix, desc = \"Computing qsd2_w2 similarities...\", similarity = 'hellinger')\n",
    "qst1_w2_similarities = sim.compute_similarities(qs = qst1_w2_feature_matrix, db_feature_matrix = db_feature_matrix, desc = \"Computing qst1_w2 similarities...\", similarity = 'hellinger')\n",
    "qst2_w2_similarities = sim.compute_similarities(qs = qst2_w2_feature_matrix, db_feature_matrix = db_feature_matrix, desc = \"Computing qst2_w2 similarities...\", similarity = 'hellinger')\n",
    "\n",
    "# Get top K\n",
    "top_k_qsd2_w1 = get_top_k(similarity_matrix=qs2_w1_similarities,k=10,desc=\"Retrieving qsd2_w1 top K similar images...\")\n",
    "top_k_qsd1_w2 = get_top_k(similarity_matrix=qs1_w2_similarities,k=10,desc=\"Retrieving qsd1_w2 top K similar images...\")\n",
    "top_k_qsd2_w2 = get_top_k(similarity_matrix=qs2_w2_similarities,k=10,desc=\"Retrieving qsd2_w2 top K similar images...\")\n",
    "top_k_qst1_w2 = get_top_k(similarity_matrix=qst1_w2_similarities,k=10,desc=\"Retrieving qst1_w2 top K similar images...\")\n",
    "top_k_qst2_w2 = get_top_k(similarity_matrix=qst2_w2_similarities,k=10,desc=\"Retrieving qst2_w2 top K similar images...\")\n",
    "\n",
    "predicted_results = save_results(top_k_qst1_w2,\"./week2/QST1/method1\",save=True)\n",
    "\n",
    "\n",
    "# Evaluation and Saving\n",
    "predicted_results = save_results(top_k_qsd2_w1,\"./week1/QST2/method1\",save=False)\n",
    "expected_results = pickle.load(open('./data/qsd2_w1/gt_corresps.pkl', \"rb\"))\n",
    "metric = metrics.mapk(actual=expected_results,predicted=predicted_results,k=1)\n",
    "print(\"MAP@K Score(ostsu): {:.4f}% ({}/{})\".format(metric*100,int(len(predicted_results)*metric),len(predicted_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# White Background Black Letters\n",
    "def get_cropped_contours(im,kernel_size=(10,7)):\n",
    "    lower = np.array([0, 0, 0])\n",
    "    upper = np.array([35, 35, 35])\n",
    "    mask = cv2.inRange(im, lower, upper)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, kernel_size)\n",
    "    dilate = cv2.dilate(mask, kernel, iterations=2)\n",
    "\n",
    "    cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "\n",
    "    candidates = []\n",
    "\n",
    "    for c in cnts:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        area = h*w\n",
    "        if area >= 20000 and h >= 200:\n",
    "            text = im[y:y + h, x:x + w]\n",
    "            candidates.append((area, text))\n",
    "    \n",
    "    return candidates\n",
    "\n",
    "def crop(im):\n",
    "    \n",
    "    candidates = get_cropped_contours(im)\n",
    "\n",
    "    try:\n",
    "        cropped = [max(candidates)[1]]\n",
    "        \n",
    "    except:\n",
    "        i_1,j_1 = 3,1\n",
    "        i_2,j_2 = 2,2\n",
    "        candidates = get_cropped_contours(im,(7,7))\n",
    "        while not candidates:\n",
    "            i_1,j_1 = i_1+2,j_1+1\n",
    "            i_2,j_2 = i_1+2,j_1+2\n",
    "\n",
    "            candidates = get_cropped_contours(im,(i_1,j_1))\n",
    "            if not candidates:\n",
    "                candidates = get_cropped_contours(im,(i_2,j_2))\n",
    "\n",
    "    \n",
    "    try:\n",
    "        cropped = [max(candidates)[1]]    \n",
    "        candidates.remove(max(candidates))\n",
    "    except:\n",
    "        print(candidates)\n",
    "        \n",
    "    if len(candidates) >= 3:\n",
    "        cropped.append(max(candidates)[1])\n",
    "    \n",
    "    f, axarr = plt.subplots(1,len(cropped)+1, figsize=(10,10))\n",
    "\n",
    "    axarr[0].imshow(im)\n",
    "    for i in range(len(cropped)):\n",
    "        axarr[i+1].imshow(cropped[i])\n",
    "\n",
    "    plt.show()\n",
    "    return cropped\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def otsus_binarization(gray_image: np.ndarray) -> float:\n",
    "\n",
    "    # Histogram\n",
    "    hist, bin_edges = np.histogram(gray_image, bins=256)\n",
    "\n",
    "    # Medium from bins\n",
    "    bin_mids = (bin_edges[:-1] + bin_edges[1:]) / 2.\n",
    "\n",
    "    # Get the probabilities w1(t), w2(t) with the accumulative probability/distribution of intensities\n",
    "    w1 = np.cumsum(hist)\n",
    "    w2 = np.cumsum(hist[::-1])[::-1]\n",
    "\n",
    "    # Class 1 Mean\n",
    "    sigma1 = np.cumsum(hist * bin_mids) / w1\n",
    "    \n",
    "    # Class 2 Mean\n",
    "    sigma2 = (np.cumsum((hist * bin_mids)[::-1]) / w2[::-1])[::-1]\n",
    "\n",
    "    # Variances\n",
    "    variance_between_classes = w1[:-1] * w2[1:] * (sigma1[:-1] - sigma2[1:]) ** 2\n",
    "\n",
    "    # Maximize the inter_class_variance function val aka the threshold\n",
    "    idx_max_variance = np.argmax(variance_between_classes)\n",
    "    th = bin_mids[:-1][idx_max_variance]\n",
    "    \n",
    "    # print(\"Threshold found: {} ({} if not normalized)\".format(th,th*255))\n",
    "    \n",
    "    # Generate Mask\n",
    "    gray_image[gray_image >= th] = 1\n",
    "    gray_image[gray_image <= th] = 0\n",
    "    \n",
    "    \n",
    "    return gray_image\n",
    "\n",
    "\n",
    "def crop_image(mask: np.ndarray) -> List[List[int]]:\n",
    "    mid_i, mid_j = int(mask.shape[0]/2),int(mask.shape[1]/2)\n",
    "    offset = 50\n",
    "    \n",
    "    mid_row = mask[mid_i,:]\n",
    "    mid_col = mask[:,mid_j]\n",
    "    \n",
    "    left = np.where(mid_row == 0)[0][0]\n",
    "    right = np.where(mid_row == 0)[0][-1]\n",
    "    top = np.where(mid_col == 0)[0][0]\n",
    "    bot = np.where(mid_col == 0)[0][-1]\n",
    "    \n",
    "    new_mask = np.zeros_like(mask)\n",
    "    new_mask[top:bot,left:right] = 1\n",
    "    \n",
    "    return new_mask, (top,bot,left,right)\n",
    "\n",
    "\n",
    "def crop_image_2(mask: np.ndarray) -> List[List[int]]:\n",
    "    # Mid Column and Mid Row\n",
    "    mid_i, mid_j = int(mask.shape[0]/2),int(mask.shape[1]/2)\n",
    "    mid_row = mask[mid_i,:]\n",
    "    mid_col = mask[:,mid_j]\n",
    "    # Offset to initial points\n",
    "    offset = 50\n",
    "    th = 0.15\n",
    "    \n",
    "    top = None\n",
    "    bot = None\n",
    "    left = None\n",
    "    right = None\n",
    "    \n",
    "    # Search left boundary\n",
    "    found = False\n",
    "    i = offset\n",
    "    \n",
    "\n",
    "    while not found:\n",
    "        if abs(mid_row[i] - mid_row[i-1]) >= th: \n",
    "            found = True\n",
    "            left = i\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    # Search right boundary\n",
    "    found = False\n",
    "    i = mid_row.shape[0] - 1\n",
    "    while not found:\n",
    "        if abs(mid_row[i] - mid_row[i-1]) >= th:\n",
    "            found = True\n",
    "            right = i\n",
    "        i -= 1\n",
    "\n",
    "\n",
    "    # Search top boundary\n",
    "    found = False\n",
    "    j = 0\n",
    "    while not found:\n",
    "        if abs(mid_col[j] - mid_col[j-1]) >= th:\n",
    "            found = True\n",
    "            top = j\n",
    "        j += 1\n",
    "\n",
    "    # Search bot boundary\n",
    "    found = False\n",
    "    j = mid_col.shape[0] - 1\n",
    "    while not found:\n",
    "        if abs(mid_col[j] - mid_col[j-1]) >= th:\n",
    "            found = True\n",
    "            bot = j\n",
    "        j -= 1\n",
    "\n",
    "    new_mask = np.zeros_like(mask)\n",
    "    new_mask[top:bot,left:right] = 1\n",
    "\n",
    "    return new_mask, (top,bot,left,right)\n",
    "\n",
    "\n",
    "\n",
    "def crop_images(qs: np.ndarray, method: str) -> Tuple[List[np.ndarray], List[np.ndarray]]:\n",
    "    masks, cropped_images = [], []\n",
    "    \n",
    "    if method == \"otsu\":\n",
    "        for image in tqdm(qs, desc= \"Cropping Images using Otsu method...\"):\n",
    "            im = otsus_binarization(rgb2gray(image))\n",
    "            mask, coords = crop_image(im)\n",
    "            cropped_image = image[coords[0]:coords[1], coords[2]:coords[3],:]\n",
    "            masks.append(mask)\n",
    "            cropped_images.append(cropped_image)\n",
    "                    \n",
    "    elif method == \"diff\":\n",
    "        for image in tqdm(qs, desc= \"Cropping Images using Pixel Diff method...\"):\n",
    "            im = rgb2gray(image)\n",
    "            try:\n",
    "                mask, coords = crop_image_2(im)\n",
    "                cropped_image = image[coords[0]:coords[1], coords[2]:coords[3]]\n",
    "            except:\n",
    "                mask = np.zeros_like(image)\n",
    "                mask[int(mask.shape[0]*0.25):,:,:] = [1,1,1]\n",
    "                mask[int(mask.shape[0]*0.75):,:] = [1,1,1]\n",
    "                mask[:,:int(mask.shape[1]*0.25),:] = [1,1,1]\n",
    "                mask[:,int(mask.shape[1]*0.75):,:] = [1,1,1]\n",
    "                cropped_image = image[int(image.shape[0]*0.25):int(image.shape[0]*0.75),int(image.shape[1]*0.25):int(image.shape[1]*0.75),:]\n",
    "            \n",
    "            masks.append(mask)\n",
    "            cropped_images.append(cropped_image)\n",
    "            \n",
    "\n",
    "                \n",
    "    return cropped_images, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_and_windows(images: np.ndarray, n_cols: int, n_rows: int) -> None:\n",
    "    for im in images:\n",
    "        windows = image_to_windows(im, n_cols=n_cols, n_rows=n_rows)\n",
    "        f, axarr = plt.subplots(4,4, figsize=(15,15))\n",
    "        for i in range(n_rows):\n",
    "            for j in range(n_cols):\n",
    "                axarr[i,j].imshow(windows[j+i*n_rows])\n",
    "                \n",
    "        plt.savefig('tmp.png')\n",
    "        plt.clf() \n",
    "        f, axarr = plt.subplots(1,2, figsize=(15,15))\n",
    "        windows = imread('tmp.png')\n",
    "        axarr[0].imshow(windows)\n",
    "        axarr[1].imshow(im)\n",
    "        plt.show()\n",
    "        os.remove('tmp.png')\n",
    "        \n",
    "        \n",
    "plot_image_and_windows(db[:2], 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02c6bba27ce5da84fd9746f275d4e3433f7ae6fedab4e6fa066c87aa23a6ecf9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
